{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignement 3 - Linear regression with Multiple variables\n",
    "\n",
    "\n",
    "In this third assignment, you will implement linear regression with multiple variables and get to see it work on data. \n",
    "\n",
    "In this part, you will implement linear regression with multiple variables to predict the prices of houses. Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to first collect information on recent houses sold and make a model of housing prices.\n",
    "\n",
    "The file LRdata2.txt contains a training set of housing prices (for example in your city). The first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price of the house.\n",
    "\n",
    "You work is to complete the assignement 3 by filling the missing lines of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some useful libraries to use in this assignment\n",
    "\n",
    "\n",
    "from numpy import loadtxt, zeros, ones, array, linspace, logspace, mean, std, arange\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import plot, show, xlabel, ylabel, scatter, title, plot, contour\n",
    "import matplotlib\n",
    "import copy\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step\n",
    "\n",
    "We are going to plot the dataset and see if we can apply linear regression to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Load the dataset\n",
    "data = loadtxt('LRdata2.txt', delimiter=',')\n",
    "\n",
    "\n",
    "#Plot the data\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "n = 100\n",
    "for c, m, zl, zh in [('r', 'o', -50, -25)]:\n",
    "    xs = data[:, 0]\n",
    "    ys = data[:, 1]\n",
    "    zs = data[:, 2]\n",
    "    ax.scatter(xs, ys, zs, c=c, marker=m)\n",
    "ax.set_xlabel('Size of the House')\n",
    "ax.set_ylabel('Number of Bedrooms')\n",
    "ax.set_zlabel('Price of the House')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "You have to complete the function feature_normalization in order to normalize our inputs and also to get gradient descent works well in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluate the linear regression\n",
    "\n",
    "def feature_normalization(X):\n",
    "    '''\n",
    "    Returns a normalized version of X where the mean value of each feature is 0 and the standard deviation\n",
    "    is 1. We presented that in the supplementary material.\n",
    "    '''\n",
    "    mean_r = []\n",
    "    std_r = []\n",
    "\n",
    "    X_norm = copy.copy(X)\n",
    "    \n",
    "    # The variable \"it\" represents the number of features. We will proceed for each one using a for loop.\n",
    "    it = X.shape[1] \n",
    "    for i in range(it):\n",
    "        # Your code goes here \n",
    "        \n",
    "        \n",
    "        # End of your code\n",
    "\n",
    "    return X_norm, mean_r, std_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your code for \"feature_normalization\" function\n",
    "\n",
    "You should see results like this :\n",
    "\n",
    "0.962801191824\n",
    "0.00999072667146\n",
    "1.00362503123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, m, s = feature_normalization(data[:, :2])\n",
    "print (\"Mean : Feature 1 = %.2f and Feature 2 = %.2f\" % (m[0], m[1]))\n",
    "print (\"Standard deviation : Feature 1 = %.2f and feature 2 : %.2f\" % (s[0], s[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "You have to complete the function compute_cost that has three parameters: X, y and W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, y, W):\n",
    "    '''\n",
    "    Compute cost for linear regression\n",
    "    '''\n",
    "    # Your code goes here \n",
    "    \n",
    "    \n",
    "    # End of your code\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your code for \"compute_cost\" function\n",
    "\n",
    "You should see results like this :\n",
    "\n",
    "The initial cost : 6.55915481e+10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "m = y.size\n",
    "y.shape = (m, 1)\n",
    "\n",
    "# Scale features and set them to zero mean\n",
    "x, mean_r, std_r = feature_normalization(X)\n",
    "\n",
    "# Add a column of ones to X (interception data)\n",
    "new_X = ones(shape=(m, 3))\n",
    "new_X[:, 1:3] = X\n",
    "\n",
    "# Init W and Run Gradient Descent\n",
    "W = zeros(shape=(3, 1))\n",
    "\n",
    "J = compute_cost(new_X, y, W)\n",
    "print (\"The initial cost : \" + str(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "You have to complete the function gradient_descent that has five parameters: X, y, W, alpha and num_iters\n",
    "\n",
    "alpha: the learning rate\n",
    "\n",
    "num_iters: the number of iterations before we find the best parameters Ws.\n",
    "\n",
    "N.B. You should remember that maybe we will have more parameters W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, W, alpha, num_iters):\n",
    "    '''\n",
    "    Performs gradient descent to learn W by taking num_items gradient steps with learning rate alpha\n",
    "    '''\n",
    "    m = y.size\n",
    "    \n",
    "    \"\"\"\n",
    "        This variable J_prev will keep truck of the previous values of J in order to use them to plot the cost J\n",
    "        in the last part\n",
    "    \"\"\"\n",
    "    J_prev = zeros(shape=(num_iters, 1)) # \n",
    "\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        # Your code goes here \n",
    "\n",
    "        \n",
    "        # End of your code\n",
    "\n",
    "    return W, J_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "You have to complete the next cell by giving values to two variables: iterations and alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model hyperparameters. Play with them by changing their values and see what happened\n",
    "\"\"\"\n",
    "    In this cell, you should try with different values of the following variables : \n",
    "    - iterations : which will the number of times gradient descent will take before it converges to\n",
    "        the minimum\n",
    "        \n",
    "    - alpha : the learning rate. Try these values : 0.01 and 0.02 and 0.03.\n",
    "\"\"\"\n",
    "# Your initialization goes here\n",
    "\n",
    "\n",
    "# End of your initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "You have to complete the next cell by computing the initial cost, after that computing W after apply gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "\n",
    "\n",
    "# Number of training samples\n",
    "m = y.size\n",
    "\n",
    "y.shape = (m, 1)\n",
    "\n",
    "# Scale features and set them to zero mean\n",
    "x, mean_r, std_r = feature_normalization(X)\n",
    "\n",
    "# Add a column of ones to X (interception data)\n",
    "new_X = ones(shape=(m, 3))\n",
    "new_X[:, 1:3] = x\n",
    "\n",
    "# Init W and Run Gradient Descent\n",
    "W = zeros(shape=(3, 1))\n",
    "\n",
    "\n",
    "# Compute and print the initial cost. Print W after applying gradient descent\n",
    "\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "\n",
    "# End of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cost\n",
    "\n",
    "In the cell, you will see the behaviour of the cost after a number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(arange(iterations), J_history)\n",
    "xlabel('Iterations')\n",
    "ylabel('Cost Function')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict price of a 2000 sq-ft 3 br house\n",
    "\n",
    "feet_sq = 3000.0 # You can try different values here and see the corresponding prices\n",
    "nb_bedrooms = 2\n",
    "\n",
    "feature1 = ((feet_sq - mean_r[0]) / std_r[0])\n",
    "feature2 = ((nb_bedrooms - mean_r[1]) / std_r[1])\n",
    "\n",
    "price = array([1.0, feature1, feature2]).dot(W)\n",
    "\n",
    "print ('The price of a house with %.2f sq-ft and %d bedrooms is : %.2f' % (feet_sq, nb_bedrooms, price))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
